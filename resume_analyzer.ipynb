{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get The text from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pdfplumber\n",
      "  Downloading pdfplumber-0.11.6-py3-none-any.whl.metadata (42 kB)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.13)\n",
      "Collecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting pdfminer.six==20250327 (from pdfplumber)\n",
      "  Downloading pdfminer_six-20250327-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pdfplumber) (11.1.0)\n",
      "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
      "  Downloading pypdfium2-4.30.1-py3-none-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pdfminer.six==20250327->pdfplumber) (3.4.1)\n",
      "Collecting cryptography>=36.0.0 (from pdfminer.six==20250327->pdfplumber)\n",
      "  Downloading cryptography-45.0.3-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from cffi>=1.14->cryptography>=36.0.0->pdfminer.six==20250327->pdfplumber) (2.22)\n",
      "Downloading pdfplumber-0.11.6-py3-none-any.whl (60 kB)\n",
      "Downloading pdfminer_six-20250327-py3-none-any.whl (5.6 MB)\n",
      "   ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 3.1/5.6 MB 17.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.6 MB 17.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.6 MB 7.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 5.0/5.6 MB 6.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.6/5.6 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Downloading pypdfium2-4.30.1-py3-none-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.0/3.0 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 2.9/3.0 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 7.0 MB/s eta 0:00:00\n",
      "Downloading cryptography-45.0.3-cp311-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 1.0/3.4 MB 5.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.1/3.4 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.1/3.4 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 4.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pypdfium2, pdf2image, cryptography, pdfminer.six, pdfplumber\n",
      "Successfully installed cryptography-45.0.3 pdf2image-1.17.0 pdfminer.six-20250327 pdfplumber-0.11.6 pypdfium2-4.30.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pdfplumber pytesseract pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        # Try direct text extraction\n",
    "        with pdfplumber.open(pdf_path) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                page_text = page.extract_text()\n",
    "                if page_text:\n",
    "                    text += page_text\n",
    "\n",
    "        if text.strip():\n",
    "            return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Direct text extraction failed: {e}\")\n",
    "\n",
    "    # Fallback to OCR for image-based PDFs\n",
    "    print(\"Falling back to OCR for image-based PDF.\")\n",
    "    try:\n",
    "        images = convert_from_path(pdf_path)\n",
    "        for image in images:\n",
    "            page_text = pytesseract.image_to_string(image)\n",
    "            text += page_text + \"\\n\"\n",
    "    except Exception as e:\n",
    "        print(f\"OCR failed: {e}\")\n",
    "\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text from PDF:\n",
      "KEERTI J\n",
      "jkeerti550@gmail.com || 9150521729\n",
      "GITHUB LINKEDIN LEETCODE CODECHEF HACKERRANK CODING NINJAS\n",
      "SUMMARY\n",
      "Enthusiastic computer science and engineering student specializing in artificial intelligence and machine learning. A\n",
      "detail-oriented and analytical thinker with strong programming skills in C++. complemented by hands-on experience in\n",
      "UI/UX design. Committed to leveraging technology to solve real-world problems and enhance user experiences.\n",
      "WORK EXPERIENCE\n",
      "TANSAM , Chennai\n",
      "Artificial Intelligence And Machine Learning\n",
      "Did my internship offered by Tamilnadu smart and advanced manufacturing centre (TANSAM).\n",
      "Did projects based on linear and logistic regression.\n",
      "Cancer detection project based on the dataset given by wisconsin.\n",
      "EDUCATION\n",
      "Bachelor of Engineering (B.E.) in Computer Science and Engineering (Artificial Intelligence and Machine\n",
      "Learning)\n",
      "Easwari engineering college GPA: 8.8\n",
      "Chennai Higher Sec School\n",
      "Did Schooling from 5th - 12th\n",
      "Metro English Medium School\n",
      "Did Schooling till 4th\n",
      "ACHIEVEMENTS\n",
      "Showcased project at IEEE Day 2024 Project Showdown.\n",
      "Participated, AIML Challenge – IIT Madras.\n",
      "Completed SAWiT.AI Learnathon Challenge.\n",
      "Participated in Infosys Springboard Ideathon.\n",
      "Developed prototype at Hacker Ramp Hackathon.\n",
      "Solved 400+ problems on LeetCode (DSA & algorithms).\n",
      "NPTEL Elite certifications in IoT.\n",
      "NPTEL Elite certifications Human-Computer Interaction.\n",
      "TECH SKILLS SOFT SKILLS TOOLS & TECHNOLOGY\n",
      "C++ (Advanced)\n",
      "Teamwork Figma\n",
      "Python (Intermediate) Time Management Canva\n",
      "Java (Basics) Microsoft word\n",
      "Leadership\n",
      "Excel\n",
      "R (Basics)\n",
      "Effective Communication Git & GitHub\n",
      "HTML, CSS (Intermediate)\n",
      "Critical Thinking\n",
      "Javascript (Basic)\n",
      "C programmingVOLUNTEERING\n",
      "Campus Ambassador\n",
      "E-Cell, IIT Bombay: Promoted entrepreneurial initiatives and facilitated student engagement on behalf of IIT\n",
      "Bombay’s Entrepreneurship Cell.\n",
      "Member – Google Developer Student Club (GDSC)\n",
      "Participated in technical workshops and collaborative development activities.\n",
      "Head of Operations – ENLIT Literary Club\n",
      "Led event planning and team coordination to foster creative expression through club initiatives.\n",
      "Student Member – Computer Society of India (CSI)\n",
      "Attended technical seminars and engaged with industry professionals to enhance computing knowledge.\n",
      "Volunteer Member – Youth Red Cross (YRC):\n",
      "Supported health awareness drives, social service activities, and disaster relief efforts.\n",
      "PROJECTS\n",
      "Heart Disease Detection\n",
      "Built a predictive ML model achieving 90% accuracy in assessing heart disease risk.\n",
      "AI Skill Navigator(Ongoing)\n",
      "Developing a full-stack AI-powered web app to recommend personalized career paths and learning resources for\n",
      "students based on their skills and interests.\n",
      "GLOF (Glacier Early Warning Flood System)\n",
      "Created ML models for time-series analysis to optimize supply chain and inventory management.\n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"Keerti J - EEC- CSE(AIML).pdf\"\n",
    "resume_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "print(\"\\nExtracted Text from PDF:\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Google GenerativeAI Api Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.generativeai\n",
      "  Downloading google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.1)\n",
      "Collecting google-ai-generativelanguage==0.6.15 (from google.generativeai)\n",
      "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Downloading google_api_core-2.24.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-api-python-client (from google.generativeai)\n",
      "  Downloading google_api_python_client-2.170.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting google-auth>=2.15.0 (from google.generativeai)\n",
      "  Downloading google_auth-2.40.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: protobuf in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google.generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google.generativeai) (2.10.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google.generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google.generativeai) (4.12.2)\n",
      "Collecting google-api-core (from google.generativeai)\n",
      "  Downloading google_api_core-2.25.0rc1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading proto_plus-1.26.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting googleapis-common-protos<2.0.0,>=1.56.2 (from google-api-core->google.generativeai)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core->google.generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (5.5.2)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=2.15.0->google.generativeai)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google.generativeai) (4.9)\n",
      "Collecting httplib2<1.0.0,>=0.19.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2<1.0.0,>=0.2.0 (from google-api-python-client->google.generativeai)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting uritemplate<5,>=3.0.1 (from google-api-python-client->google.generativeai)\n",
      "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google.generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google.generativeai) (2.27.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->google.generativeai) (0.4.6)\n",
      "Collecting grpcio<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio-1.71.0-cp313-cp313-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google.generativeai)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google.generativeai) (3.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google.generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\keerti\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google.generativeai) (2025.1.31)\n",
      "Downloading google_generativeai-0.8.5-py3-none-any.whl (155 kB)\n",
      "Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading google_api_core-2.25.0rc1-py3-none-any.whl (160 kB)\n",
      "Downloading google_auth-2.40.2-py2.py3-none-any.whl (216 kB)\n",
      "Downloading google_api_python_client-2.170.0-py3-none-any.whl (13.5 MB)\n",
      "   ---------------------------------------- 0.0/13.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/13.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/13.5 MB 2.8 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 2.4/13.5 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 3.7/13.5 MB 4.2 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.2/13.5 MB 4.1 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.5/13.5 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 4.7/13.5 MB 3.3 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 5.2/13.5 MB 3.2 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 5.8/13.5 MB 3.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 6.3/13.5 MB 3.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 7.1/13.5 MB 3.0 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 7.9/13.5 MB 3.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.9/13.5 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 10.2/13.5 MB 3.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 10.7/13.5 MB 3.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 11.3/13.5 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 12.6/13.5 MB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.5/13.5 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading proto_plus-1.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading grpcio-1.71.0-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.8/4.3 MB 4.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.6/4.3 MB 3.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.4/4.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 3.6 MB/s eta 0:00:00\n",
      "Downloading grpcio_status-1.71.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: uritemplate, pyasn1-modules, proto-plus, httplib2, grpcio, googleapis-common-protos, grpcio-status, google-auth, google-auth-httplib2, google-api-core, google-api-python-client, google-ai-generativelanguage, google.generativeai\n",
      "Successfully installed google-ai-generativelanguage-0.6.15 google-api-core-2.25.0rc1 google-api-python-client-2.170.0 google-auth-2.40.2 google-auth-httplib2-0.2.0 google.generativeai-0.8.5 googleapis-common-protos-1.70.0 grpcio-1.71.0 grpcio-status-1.71.0 httplib2-0.22.0 proto-plus-1.26.1 pyasn1-modules-0.4.2 uritemplate-4.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install google.generativeai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Keerti\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.generate_content(\"What is the capital of India?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response:\n",
      "GenerateContentResponse(\n",
      "    done=True,\n",
      "    iterator=None,\n",
      "    result=protos.GenerateContentResponse({\n",
      "      \"candidates\": [\n",
      "        {\n",
      "          \"content\": {\n",
      "            \"parts\": [\n",
      "              {\n",
      "                \"text\": \"The capital of India is **New Delhi**.\\n\"\n",
      "              }\n",
      "            ],\n",
      "            \"role\": \"model\"\n",
      "          },\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"avg_logprobs\": -0.0026347806677222254\n",
      "        }\n",
      "      ],\n",
      "      \"usage_metadata\": {\n",
      "        \"prompt_token_count\": 7,\n",
      "        \"candidates_token_count\": 10,\n",
      "        \"total_token_count\": 17\n",
      "      },\n",
      "      \"model_version\": \"gemini-1.5-flash\"\n",
      "    }),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **New Delhi**.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resume Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_resume(resume_text, job_description=None):\n",
    "    if not resume_text:\n",
    "        return {\"error\": \"Resume text is required for analysis.\"}\n",
    "    \n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    \n",
    "    base_prompt = f\"\"\"\n",
    "    You are an experienced HR with Technical Experience in the field of any one job role from Data Science, Data Analyst, DevOPS, Machine Learning Engineer, Prompt Engineer, AI Engineer, Full Stack Web Development, Big Data Engineering, Marketing Analyst, Human Resource Manager, Software Developer your task is to review the provided resume.\n",
    "    Please share your professional evaluation on whether the candidate's profile aligns with the role.ALso mention Skills he already have and siggest some skills to imorve his resume , alos suggest some course he might take to improve the skills.Highlight the strengths and weaknesses.\n",
    "\n",
    "    Resume:\n",
    "    {resume_text}\n",
    "    \"\"\"\n",
    "\n",
    "    if job_description:\n",
    "        base_prompt += f\"\"\"\n",
    "        Additionally, compare this resume to the following job description:\n",
    "        \n",
    "        Job Description:\n",
    "        {job_description}\n",
    "        \n",
    "        Highlight the strengths and weaknesses of the applicant in relation to the specified job requirements.\n",
    "        \"\"\"\n",
    "\n",
    "    response = model.generate_content(base_prompt)\n",
    "\n",
    "    analysis = response.text.strip()\n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Resume Review: Keerti J\n",
      "\n",
      "**Target Role (Assumption):**  Given the resume content, I'm assuming the target role is a junior-level Data Scientist or Machine Learning Engineer.\n",
      "\n",
      "**Overall Assessment:** Keerti's resume demonstrates a strong foundation in programming and AI/ML, bolstered by impressive extracurricular activities and project experience. However, it needs refinement to better showcase his skills and align with industry expectations.\n",
      "\n",
      "**Strengths:**\n",
      "\n",
      "* **Strong Programming Foundation:**  Proficiency in C++ (advanced) is a significant advantage.  Python (intermediate) is also crucial for data science.\n",
      "* **Relevant Projects:** The projects (Heart Disease Detection, AI Skill Navigator, GLOF) showcase practical application of ML concepts.  Quantifiable results (90% accuracy) are excellent.\n",
      "* **Impressive Extracurricular Activities:**  The involvement in various clubs (E-Cell, GDSC, ENLIT, CSI, YRC) highlights leadership, teamwork, and a proactive attitude—highly valued qualities.  These experiences fill in gaps where work experience is limited.\n",
      "* **Problem-Solving Skills:** 400+ LeetCode problems solved demonstrates dedication and a strong grasp of algorithms and data structures.\n",
      "* **Certifications:** NPTEL certifications in IoT and HCI are valuable additions.\n",
      "\n",
      "\n",
      "**Weaknesses:**\n",
      "\n",
      "* **Work Experience:** The internship at TANSAM is described vaguely.  It needs more detail on responsibilities, achievements, and technologies used.  Quantifiable results are missing (e.g., \"Improved model accuracy by X%\").\n",
      "* **Skill Descriptions:**  \"Intermediate,\" \"Basic,\" and \"Advanced\" are subjective.  Instead, provide specific examples demonstrating skill level (e.g., \"Developed and deployed a REST API using Python's Flask framework\").\n",
      "* **Resume Structure:** The resume is a bit cluttered.  Consider using a more modern and visually appealing format.  The \"Summary\" could be stronger and more targeted towards specific roles.\n",
      "* **AI Skill Navigator Project:**  While ambitious, \"ongoing\" projects should be carefully evaluated.  If not substantially complete, focus on finished projects first.\n",
      "* **Lack of Deep Learning Experience:**  The resume doesn't explicitly mention experience with deep learning frameworks (TensorFlow, PyTorch), which are essential for many data science roles.\n",
      "\n",
      "\n",
      "**Skills Keerti Already Has:**\n",
      "\n",
      "* **Programming Languages:** C++, Python, Java (basics), R (basics), JavaScript (basics), C\n",
      "* **Machine Learning:** Linear Regression, Logistic Regression, Time Series Analysis\n",
      "* **Data Science Tools:**  Excel, Git, GitHub, Figma, Canva\n",
      "* **Web Development (basics):** HTML, CSS, (implied JavaScript)\n",
      "* **Soft Skills:** Teamwork, Time Management, Leadership, Communication, Critical Thinking\n",
      "\n",
      "\n",
      "**Skills to Improve:**\n",
      "\n",
      "* **Deep Learning Frameworks:** TensorFlow/Keras, PyTorch\n",
      "* **Cloud Computing:** AWS, Azure, GCP (at least foundational knowledge)\n",
      "* **Databases:** SQL (MySQL, PostgreSQL), NoSQL (MongoDB)\n",
      "* **Data Visualization:** Matplotlib, Seaborn, Tableau, Power BI\n",
      "* **Model Deployment:** Docker, Kubernetes (basic understanding)\n",
      "* **Big Data Technologies (Optional but beneficial):** Spark, Hadoop\n",
      "\n",
      "\n",
      "**Suggested Courses:**\n",
      "\n",
      "* **Deep Learning Specialization (Coursera/edX):**  Provides in-depth knowledge of deep learning frameworks and techniques.\n",
      "* **Data Structures and Algorithms (Coursera/Udemy):** Further enhance DSA skills.  Focus on advanced algorithms and data structures.\n",
      "* **Cloud Computing Fundamentals (AWS/Azure/GCP):** Learn the basics of cloud services and how to deploy applications.\n",
      "* **SQL for Data Science (DataCamp/Udemy):**  Master SQL for data manipulation and querying.\n",
      "* **Data Visualization with [Choose your tool] (DataCamp/Udemy):** Learn to effectively communicate insights through data visualizations.\n",
      "\n",
      "\n",
      "**Revised Resume Suggestions:**\n",
      "\n",
      "1. **Quantify Achievements:**  Add numbers to illustrate accomplishments.  Instead of \"Did projects based on linear and logistic regression,\" write \"Developed and deployed a logistic regression model achieving 85% accuracy in classifying customer churn.\"\n",
      "2. **Use Action Verbs:** Start bullet points with strong action verbs (e.g., \"Developed,\" \"Implemented,\" \"Optimized\").\n",
      "3. **Focus on Results:**  Emphasize the impact of your work.  What problems did you solve? How did you contribute to the team's success?\n",
      "4. **Tailor to Specific Roles:** Adjust the summary and skills section to match the requirements of each job application.\n",
      "5. **Modernize the Format:** Use a clean and professional resume template.\n",
      "6. **Expand on Projects:**  Provide more details on the technologies, challenges, and solutions for each project.\n",
      "\n",
      "\n",
      "By addressing these weaknesses and incorporating the suggested improvements, Keerti can significantly strengthen his resume and increase his chances of landing a desirable role.  The strong foundation is there; it just needs polishing to shine.\n"
     ]
    }
   ],
   "source": [
    "print(analyze_resume(resume_text))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
